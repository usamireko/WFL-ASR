# high resource config for 4+ hours of data
data:
  data_dir: "training_dataset"
  sample_rate: 16000
  num_val_files: 8
  max_seq_len: null
  frame_duration: 0.02
  n_mels: 80

model:
  encoder_type: "whisper"
  whisper_model: "openai/whisper-base" 
  wavlm_model: "microsoft/wavlm-base-plus"
  
  # unfreeze almost half the encoder for deep finetuning
  freeze_encoder: true 
  unfreeze_last_n_layers: 6 
  
  num_conformer_layers: 6 
  conformer_heads: 8
  conformer_ff_expansion: 4
  conformer_kernel_size: 31
  conformer_dropout: 0.1

  enable_dilated_conv: true
  dilated_conv_depth: 3
  dilated_conv_kernel: 3

  subframe_loss_weight: 5.0

  lang_emb_dim: 128
  num_languages: 0

training:
  batch_size: 16
  num_workers: 8
  optimizer: "AdamW"
  
  learning_rate: 0.00005 
  weight_decay: 0.001
  
  max_epochs: 1000
  check_val_every_n_epoch: 1
  
  lr_decay_every_n_epochs: 5
  lr_decay_gamma: 0.95
  
  max_checkpoints: 5
  log_dir: "logs/high"
  merged_phoneme_groups: []

augmentation:
  enable: true
  noise_std: 0.002
  prob: 0.3
  volume_range: [0.9, 1.1]

output:
  save_dir: "checkpoints_high"
  
postprocess:
  median_filter: 1
  merge_segments: "right"